{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Ng6b5COZx9Y",
        "outputId": "c74144d5-fd96-4657-849b-8dae7353eb5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCJpzqp-bhQA",
        "outputId": "86d97628-7f1d-4845-85f3-233aea1b5d34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: triton in /usr/local/lib/python3.8/dist-packages (2.0.0a1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from triton) (1.13.1+cu116)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.8/dist-packages (from triton) (3.22.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.8/dist-packages (from triton) (16.0.0rc1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from triton) (3.9.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch->triton) (4.4.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: accelerate==0.12.0 in /usr/local/lib/python3.8/dist-packages (0.12.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.26.1)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.8/dist-packages (6.1.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from accelerate==0.12.0) (6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from accelerate==0.12.0) (5.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from accelerate==0.12.0) (23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from accelerate==0.12.0) (1.21.6)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from accelerate==0.12.0) (1.13.1+cu116)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.12.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.8/dist-packages (from ftfy) (0.2.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n"
          ]
        }
      ],
      "source": [
        "%pip install -U --pre triton\n",
        "%pip install accelerate==0.12.0 transformers ftfy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bVQMLsAbG5I",
        "outputId": "9739efa7-faa8-406c-a049-01599364ad93"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/generation/utils.py:1273: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 20 (`generation_config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "arafed image of a woman in a red sweater and a red sweater,in a ddzwn style\n",
            "arafed image of a woman in a black shirt and jeans,in a ddzwn style\n",
            "there is a woman in a white shirt and black suspender,in a ddzwn style\n",
            "a woman sitting at a table with a cake and a cake,in a ddzwn style\n",
            "smiling woman in pink sweater holding a cat in a room,in a ddzwn style\n",
            "woman in red sweater and aprons cooking in a kitchen,in a ddzwn style\n",
            "arafed image of a woman sitting on a bench in a library,in a ddzwn style\n",
            "arafed image of a woman standing in a field with flowers,in a ddzwn style\n",
            "a woman in a blue dress and umbrella hat is standing on a bridge,in a ddzwn style\n",
            "a woman in a dress and a hat is sitting on a bench,in a ddzwn style\n",
            "a woman in a dress and a purse is standing on a bridge,in a ddzwn style\n",
            "arafed image of a woman standing on a bridge,in a ddzwn style\n",
            "arafed image of a woman standing on a railing railing,in a ddzwn style\n",
            "arafed image of a woman standing on a bridge over looking at the water,in a ddzwn style\n",
            "asian woman with long hair and a white shirt is posing for a picture,in a ddzwn style\n",
            "arafed image of a woman sitting on a swing set,in a ddzwn style\n",
            "a woman in a white shirt is sitting in a go kart,in a ddzwn style\n",
            "asian woman in white shirt and black pants standing on a bridge,in a ddzwn style\n",
            "woman sitting in a go kart with a helmet on,in a ddzwn style\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import requests\n",
        "import tqdm\n",
        "import os\n",
        "from PIL import Image\n",
        "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
        "\n",
        "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-large\")\n",
        "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-large\", torch_dtype=torch.float16).to(\"cuda\")\n",
        "\n",
        "# *****************************************************\n",
        "instance_dir = \"/content/drive/MyDrive/*******\"\n",
        "# *****************************************************\n",
        "\n",
        "token = \"xxx\"\n",
        "for filename in os.listdir(instance_dir):\n",
        "  \n",
        "  extension = filename.split(\".\")[-1]\n",
        "  if extension != \"txt\":\n",
        "\n",
        "    txtname = filename + \".txt\"\n",
        "    image = Image.open(instance_dir+\"/\"+filename).convert('RGB')\n",
        "\n",
        "    text = \"\"\n",
        "    inputs = processor(image, text, return_tensors=\"pt\").to(\"cuda\", torch.float16)\n",
        "\n",
        "    out = model.generate(**inputs)\n",
        "    out = processor.decode(out[0], skip_special_tokens=True)\n",
        "    prompt = token + \",\" + out\n",
        "    with open(instance_dir+\"/\"+txtname, 'w') as f:\n",
        "          f.write(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import ipywidgets as widgets\n",
        "from io import BytesIO\n",
        "#@markdown #Captions\n",
        "\n",
        "#@markdown - Open a tool to manually `create` captions or edit existing captions of the instance images.\n",
        "\n",
        "paths=\"\"\n",
        "out=\"\"\n",
        "widgets_l=\"\"\n",
        "\n",
        "instance_dir = 0 #@param\n",
        "DIR = instance_dir\n",
        "def Caption(path):\n",
        "  \n",
        "    if path!=\"Select an instance image to caption\":\n",
        "      \n",
        "      name = os.path.basename(path)\n",
        "      ext=os.path.splitext(os.path.basename(path))[-1][1:]\n",
        "      if ext==\"jpg\" or \"JPG\":\n",
        "        ext=\"JPEG\"\n",
        "      else:\n",
        "        ext=\"PNG\"      \n",
        "\n",
        "      if os.path.exists(DIR + \"/\"+ name + '.txt'):\n",
        "        with open(DIR + \"/\" + name + '.txt', 'r') as f:\n",
        "            text = f.read()\n",
        "      else:\n",
        "        with open(DIR + \"/\" + name + '.txt', 'w') as f:\n",
        "            f.write(\"\")\n",
        "            with open(DIR + \"/\" + name + '.txt', 'r') as f:\n",
        "                text = f.read()   \n",
        "\n",
        "      img=Image.open(os.path.join(DIR,path))\n",
        "      img = img.convert('RGB').resize((420, 420))\n",
        "      image_bytes = BytesIO()\n",
        "      img.save(image_bytes, format=ext, qualiy=10)\n",
        "      image_bytes.seek(0)\n",
        "      image_data = image_bytes.read()\n",
        "      img= image_data\n",
        "      image = widgets.Image(\n",
        "          value=img,\n",
        "          width=420,\n",
        "          height=420\n",
        "      )\n",
        "      text_area = widgets.Textarea(value=text, description='', disabled=False, layout={'width': '500px', 'height': '120px'})\n",
        "      \n",
        "\n",
        "      def update_text(text):\n",
        "          with open(DIR+\"/\"+ name + '.txt', 'w') as f:\n",
        "              f.write(text)\n",
        "\n",
        "      button = widgets.Button(description='Save', button_style='success')\n",
        "      button.on_click(lambda b: update_text(text_area.value))\n",
        "      \n",
        "      # return widgets.VBox([widgets.HBox([text_area, button])])\n",
        "      return widgets.HBox([image, widgets.VBox([text_area, button])])\n",
        "\n",
        "\n",
        "paths = os.listdir(DIR)\n",
        "widgets_l = widgets.Select(options=[\"Select an instance image to caption\"]+paths, rows=25)\n",
        "\n",
        "\n",
        "out = widgets.Output()\n",
        "\n",
        "def click(change):\n",
        "    with out:\n",
        "        out.clear_output()\n",
        "        display(Caption(change.new))\n",
        "\n",
        "widgets_l.observe(click, names='value')\n",
        "display(widgets.HBox([widgets_l, out]))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
