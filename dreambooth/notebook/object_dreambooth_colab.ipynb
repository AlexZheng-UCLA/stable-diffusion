{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFh6Y1Mitl7g"
      },
      "source": [
        "##DreamBooth with Stable Diffusion V2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rI3QTS5GML2k"
      },
      "source": [
        "This notebook is [KaliYuga](https://twitter.com/KaliYuga_ai)'s very basic fork of [Shivam Shrirao](https://github.com/ShivamShrirao)'s DreamBooth notebook. In addition to a vew minor formatting and QoL additions, I've added Stable Diffusion V2 as the default training option and optimized the training settings to reflect what I've found to be the best general ones. They are only suggestions; feel free to tweak anything and everything if my defaults don't do it for you.\n",
        "\n",
        "**I also [wrote a guide](https://peakd.com/hive-158694/@kaliyuga/training-a-dreambooth-model-using-stable-diffusion-v2-and-very-little-code)** that should take you through building a dataset and training a model using this notebook. If this is your first time creating a model from scratch, I reccommend you check it out!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XU7NuMAA2drw",
        "outputId": "e467e8ac-ecb0-4b25-aa4f-7323bfd07a50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Mar  2 21:29:29 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   43C    P0    26W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "#@markdown Check type of GPU and VRAM available.\n",
        "#!nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv,noheader\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5o7wVT0KHXO",
        "outputId": "7ec524fe-d724-4f3c-a00e-b4e372eee9f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#@title Login to Google Dive\n",
        "#@markdown Access Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzM7j0ZSc_9c"
      },
      "source": [
        "https://github.com/KaliYuga-ai/diffusers/tree/main/examples/dreambooth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cellView": "form",
        "id": "y4lqqWT_uxD2"
      },
      "outputs": [],
      "source": [
        "#@title Login to HuggingFace 🤗\n",
        "\n",
        "#@markdown You need to accept the model license before downloading or using the Stable Diffusion weights. Please, visit the [model card](https://huggingface.co/stabilityai/stable-diffusion-2), read the license and tick the checkbox if you agree. You have to be a registered user in 🤗 Hugging Face Hub, and you'll also need to use an access token for the code to work.\n",
        "# https://huggingface.co/settings/tokens\n",
        "!mkdir -p ~/.huggingface\n",
        "HUGGINGFACE_TOKEN = \"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\" #@param {type:\"string\"}\n",
        "!echo -n \"{HUGGINGFACE_TOKEN}\" > ~/.huggingface/token\n",
        "\n",
        "#if HUGGINGFACE_TOKEN == \"\":\n",
        "#    raise ValueError(\"No Huggingface token found\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnTMyW41cC1E"
      },
      "source": [
        "## Install Requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "PbKx-zpmGdk_",
        "outputId": "be57c9fa-f116-4ddd-e1b1-0540c5646e79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/, https://download.pytorch.org/whl/cu116\n",
            "Collecting torch==1.13.0+cu116\n",
            "  Downloading https://download.pytorch.org/whl/cu116/torch-1.13.0%2Bcu116-cp38-cp38-linux_x86_64.whl (1983.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 GB\u001b[0m \u001b[31m897.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.14.0+cu116\n",
            "  Downloading https://download.pytorch.org/whl/cu116/torchvision-0.14.0%2Bcu116-cp38-cp38-linux_x86_64.whl (24.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.2/24.2 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio==0.13.0\n",
            "  Downloading https://download.pytorch.org/whl/cu116/torchaudio-0.13.0%2Bcu116-cp38-cp38-linux_x86_64.whl (4.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchtext==0.14.0\n",
            "  Downloading torchtext-0.14.0-cp38-cp38-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.13.0+cu116) (4.5.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision==0.14.0+cu116) (8.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision==0.14.0+cu116) (2.25.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision==0.14.0+cu116) (1.22.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from torchtext==0.14.0) (4.64.1)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision==0.14.0+cu116) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision==0.14.0+cu116) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision==0.14.0+cu116) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision==0.14.0+cu116) (1.26.14)\n",
            "Installing collected packages: torch, torchvision, torchtext, torchaudio\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.13.1+cu116\n",
            "    Uninstalling torch-1.13.1+cu116:\n",
            "      Successfully uninstalled torch-1.13.1+cu116\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.14.1+cu116\n",
            "    Uninstalling torchvision-0.14.1+cu116:\n",
            "      Successfully uninstalled torchvision-0.14.1+cu116\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.14.1\n",
            "    Uninstalling torchtext-0.14.1:\n",
            "      Successfully uninstalled torchtext-0.14.1\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 0.13.1+cu116\n",
            "    Uninstalling torchaudio-0.13.1+cu116:\n",
            "      Successfully uninstalled torchaudio-0.13.1+cu116\n",
            "Successfully installed torch-1.13.0+cu116 torchaudio-0.13.0+cu116 torchtext-0.14.0 torchvision-0.14.0+cu116\n",
            "/content\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/ShivamShrirao/diffusers\n",
            "  Cloning https://github.com/ShivamShrirao/diffusers to /tmp/pip-req-build-7c5ahs81\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/ShivamShrirao/diffusers /tmp/pip-req-build-7c5ahs81\n",
            "  Resolved https://github.com/ShivamShrirao/diffusers to commit 25045fde9c4281ee317703714cc0331bb97d5a65\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from diffusers==0.13.0.dev0) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from diffusers==0.13.0.dev0) (2.25.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from diffusers==0.13.0.dev0) (8.4.0)\n",
            "Collecting huggingface-hub>=0.10.0\n",
            "  Downloading huggingface_hub-0.12.1-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from diffusers==0.13.0.dev0) (3.9.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from diffusers==0.13.0.dev0) (2022.6.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.8/dist-packages (from diffusers==0.13.0.dev0) (6.0.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.10.0->diffusers==0.13.0.dev0) (4.64.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.10.0->diffusers==0.13.0.dev0) (4.5.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.10.0->diffusers==0.13.0.dev0) (6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.10.0->diffusers==0.13.0.dev0) (23.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata->diffusers==0.13.0.dev0) (3.15.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->diffusers==0.13.0.dev0) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->diffusers==0.13.0.dev0) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->diffusers==0.13.0.dev0) (1.26.14)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->diffusers==0.13.0.dev0) (2022.12.7)\n",
            "Building wheels for collected packages: diffusers\n",
            "  Building wheel for diffusers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for diffusers: filename=diffusers-0.13.0.dev0-py3-none-any.whl size=619792 sha256=11c21004aaa4bb4ecbf7a7a18bfb1451820361f5a7199393bc05cb10c95c2db4\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-5_r9plqc/wheels/0d/9e/8d/1270500fd4690cfe806860d829f4c62130cc5e393fbbf4ed7b\n",
            "Successfully built diffusers\n",
            "Installing collected packages: huggingface-hub, diffusers\n",
            "Successfully installed diffusers-0.13.0.dev0 huggingface-hub-0.12.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting triton\n",
            "  Downloading triton-2.0.0a2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (63.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.2/63.2 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from triton) (3.9.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.8/dist-packages (from triton) (3.22.6)\n",
            "Collecting lit\n",
            "  Downloading lit-16.0.0rc3.tar.gz (144 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.0/145.0 KB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from triton) (1.13.0+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch->triton) (4.5.0)\n",
            "Building wheels for collected packages: lit\n",
            "  Building wheel for lit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lit: filename=lit-16.0.0rc3-py3-none-any.whl size=93639 sha256=1d26a636a3c57df33b8c67bda960e84085d37c437138800f6b728507746acf3b\n",
            "  Stored in directory: /root/.cache/pip/wheels/26/ec/6e/e5c5dcdf2cafb12620c431f647d296b0ccd69c9b80df70a78e\n",
            "Successfully built lit\n",
            "Installing collected packages: lit, triton\n",
            "Successfully installed lit-16.0.0rc3 triton-2.0.0a2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting accelerate==0.12.0\n",
            "  Downloading accelerate-0.12.0-py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.0/144.0 KB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers\n",
            "  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m66.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ftfy\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 KB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.37.0-py3-none-any.whl (76.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.3/76.3 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from accelerate==0.12.0) (1.13.0+cu116)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from accelerate==0.12.0) (23.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from accelerate==0.12.0) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from accelerate==0.12.0) (1.22.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from accelerate==0.12.0) (5.4.8)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.12.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m108.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.8/dist-packages (from ftfy) (0.2.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.26.14)\n",
            "Installing collected packages: tokenizers, bitsandbytes, ftfy, accelerate, transformers\n",
            "Successfully installed accelerate-0.12.0 bitsandbytes-0.37.0 ftfy-6.1.1 tokenizers-0.13.2 transformers-4.26.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gradio\n",
            "  Downloading gradio-3.19.1-py3-none-any.whl (14.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.2/14.2 MB\u001b[0m \u001b[31m84.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: natsort in /usr/local/lib/python3.8/dist-packages (5.5.0)\n",
            "Collecting pycryptodome\n",
            "  Downloading pycryptodome-3.17-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic in /usr/local/lib/python3.8/dist-packages (from gradio) (1.10.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from gradio) (3.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from gradio) (1.22.4)\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting uvicorn\n",
            "  Downloading uvicorn-0.20.0-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 KB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: markupsafe in /usr/local/lib/python3.8/dist-packages (from gradio) (2.1.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from gradio) (4.5.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from gradio) (8.4.0)\n",
            "Collecting fastapi\n",
            "  Downloading fastapi-0.92.0-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.2/56.2 KB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting markdown-it-py[linkify]>=2.0.0\n",
            "  Downloading markdown_it_py-2.2.0-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 KB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: altair>=4.2.0 in /usr/local/lib/python3.8/dist-packages (from gradio) (4.2.2)\n",
            "Collecting python-multipart\n",
            "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 KB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from gradio) (2.25.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from gradio) (1.3.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from gradio) (6.0)\n",
            "Collecting orjson\n",
            "  Downloading orjson-3.8.7-cp38-cp38-manylinux_2_28_x86_64.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.7/140.7 KB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiofiles\n",
            "  Downloading aiofiles-23.1.0-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from gradio) (3.5.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.8/dist-packages (from gradio) (2023.1.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from gradio) (3.8.4)\n",
            "Collecting websockets>=10.0\n",
            "  Downloading websockets-10.4-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.0/107.0 KB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx\n",
            "  Downloading httpx-0.23.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 KB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy\n",
            "  Downloading ffmpy-0.3.0.tar.gz (4.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting mdit-py-plugins<=0.3.3\n",
            "  Downloading mdit_py_plugins-0.3.3-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 KB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.8/dist-packages (from altair>=4.2.0->gradio) (4.3.3)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.8/dist-packages (from altair>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.8/dist-packages (from altair>=4.2.0->gradio) (0.12.0)\n",
            "Collecting mdurl~=0.1\n",
            "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Collecting linkify-it-py<3,>=1\n",
            "  Downloading linkify_it_py-2.0.0-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->gradio) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->gradio) (2.8.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->gradio) (22.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->gradio) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->gradio) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->gradio) (3.0.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->gradio) (4.0.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->gradio) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->gradio) (1.8.2)\n",
            "Collecting starlette<0.26.0,>=0.25.0\n",
            "  Downloading starlette-0.25.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 KB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpcore<0.17.0,>=0.15.0\n",
            "  Downloading httpcore-0.16.3-py3-none-any.whl (69 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.6/69.6 KB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rfc3986[idna2008]<2,>=1.3\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.8/dist-packages (from httpx->gradio) (2022.12.7)\n",
            "Collecting sniffio\n",
            "  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->gradio) (23.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->gradio) (1.4.4)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->gradio) (4.38.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->gradio) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->gradio) (0.11.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->gradio) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->gradio) (1.26.14)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->gradio) (4.0.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.8/dist-packages (from uvicorn->gradio) (8.1.3)\n",
            "Collecting h11>=0.8\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 KB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting anyio<5.0,>=3.0\n",
            "  Downloading anyio-3.6.2-py3-none-any.whl (80 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.6/80.6 KB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=3.0->altair>=4.2.0->gradio) (5.12.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=3.0->altair>=4.2.0->gradio) (0.19.3)\n",
            "Collecting uc-micro-py\n",
            "  Downloading uc_micro_py-1.0.1-py3-none-any.whl (6.2 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->gradio) (1.15.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources>=1.4.0->jsonschema>=3.0->altair>=4.2.0->gradio) (3.15.0)\n",
            "Building wheels for collected packages: ffmpy\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.0-py3-none-any.whl size=4711 sha256=96abcd002cba28d639d71c8d9c2fac28fdf573b658b00e32a672b1ea176b27f8\n",
            "  Stored in directory: /root/.cache/pip/wheels/ff/5b/59/913b443e7369dc04b61f607a746b6f7d83fb65e2e19fcc958d\n",
            "Successfully built ffmpy\n",
            "Installing collected packages: rfc3986, pydub, ffmpy, websockets, uc-micro-py, sniffio, python-multipart, pycryptodome, orjson, mdurl, h11, aiofiles, uvicorn, markdown-it-py, linkify-it-py, anyio, starlette, mdit-py-plugins, httpcore, httpx, fastapi, gradio\n",
            "Successfully installed aiofiles-23.1.0 anyio-3.6.2 fastapi-0.92.0 ffmpy-0.3.0 gradio-3.19.1 h11-0.14.0 httpcore-0.16.3 httpx-0.23.3 linkify-it-py-2.0.0 markdown-it-py-2.2.0 mdit-py-plugins-0.3.3 mdurl-0.1.2 orjson-3.8.7 pycryptodome-3.17 pydub-0.25.1 python-multipart-0.0.6 rfc3986-1.5.0 sniffio-1.3.0 starlette-0.25.0 uc-micro-py-1.0.1 uvicorn-0.20.0 websockets-10.4\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting xformers==0.0.15.dev0+4c06c79.d20221205\n",
            "  Downloading https://github.com/brian6091/xformers-wheels/releases/download/0.0.15.dev0%2B4c06c79/xformers-0.0.15.dev0+4c06c79.d20221205-cp38-cp38-linux_x86_64.whl (47.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.4/47.4 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch==1.13 in /usr/local/lib/python3.8/dist-packages (from xformers==0.0.15.dev0+4c06c79.d20221205) (1.13.0+cu116)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from xformers==0.0.15.dev0+4c06c79.d20221205) (1.22.4)\n",
            "Collecting pyre-extensions==0.0.23\n",
            "  Downloading pyre_extensions-0.0.23-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from pyre-extensions==0.0.23->xformers==0.0.15.dev0+4c06c79.d20221205) (4.5.0)\n",
            "Collecting typing-inspect\n",
            "  Downloading typing_inspect-0.8.0-py3-none-any.whl (8.7 kB)\n",
            "Collecting mypy-extensions>=0.3.0\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, typing-inspect, pyre-extensions, xformers\n",
            "Successfully installed mypy-extensions-1.0.0 pyre-extensions-0.0.23 typing-inspect-0.8.0 xformers-0.0.15.dev0+4c06c79.d20221205\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting safetensors\n",
            "  Downloading safetensors-0.2.8-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: safetensors\n",
            "Successfully installed safetensors-0.2.8\n"
          ]
        }
      ],
      "source": [
        "%pip install torch==1.13.0+cu116 torchvision==0.14.0+cu116 torchaudio==0.13.0 torchtext==0.14.0 --extra-index-url https://download.pytorch.org/whl/cu116\n",
        "%cd /content\n",
        "\n",
        "import os\n",
        "if os.path.isfile(\"/content/train_dreambooth.py\"):\n",
        "    os.unlink(\"/content/train_dreambooth.py\")\n",
        "if os.path.isfile(\"/content/convert_diffusers_to_original_stable_diffusion.py\"):\n",
        "    os.unlink(\"/content/convert_diffusers_to_original_stable_diffusion.py\")\n",
        "\n",
        "#!wget -q https://github.com/ShivamShrirao/diffusers/raw/main/examples/dreambooth/train_dreambooth.py\n",
        "# !wget -q https://github.com/ethan-team/diffusers_colab/raw/main/examples/dreambooth/train_dreambooth.py\n",
        "!wget -q https://github.com/AlexZheng-UCLA/dreambooth/raw/main/script/train_dreambooth.py\n",
        "!wget -q https://github.com/ShivamShrirao/diffusers/raw/main/scripts/convert_diffusers_to_original_stable_diffusion.py\n",
        "\n",
        "%pip install git+https://github.com/ShivamShrirao/diffusers\n",
        "%pip install -U --pre triton\n",
        "%pip install accelerate==0.12.0 transformers ftfy bitsandbytes \n",
        "%pip install gradio natsort\n",
        "\n",
        "%pip install https://github.com/brian6091/xformers-wheels/releases/download/0.0.15.dev0%2B4c06c79/xformers-0.0.15.dev0+4c06c79.d20221205-cp38-cp38-linux_x86_64.whl\n",
        "%pip install safetensors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0NV324ZcL9L"
      },
      "source": [
        "## Settings and run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rxg0y5MBudmd",
        "outputId": "657c9f6a-b085-4a91-d1b9-14f320d3d5ad",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "[*] Weights will be saved at /content/drive/MyDrive/stable_diffusion_weights/zyc\n"
          ]
        }
      ],
      "source": [
        "#@markdown If model weights should be saved directly in google drive (takes around 4-5 GB).\n",
        "save_to_gdrive = True #@param {type:\"boolean\"}\n",
        "if save_to_gdrive:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "#@markdown Name/Path of the initial model.\n",
        "MODEL_NAME = \"runwayml/stable-diffusion-v1-5\" #@param \n",
        "VAE_NAME = \"stabilityai/sd-vae-ft-mse\" #@param\n",
        "\n",
        "#@markdown Enter the directory name to save model at.\n",
        "\n",
        "OUTPUT_DIR = \"stable_diffusion_weights/zyc\" #@param {type:\"string\"}\n",
        "if save_to_gdrive:\n",
        "    OUTPUT_DIR = \"/content/drive/MyDrive/\" + OUTPUT_DIR\n",
        "else:\n",
        "    OUTPUT_DIR = \"/content/\" + OUTPUT_DIR\n",
        "\n",
        "print(f\"[*] Weights will be saved at {OUTPUT_DIR}\")\n",
        "\n",
        "!mkdir -p $OUTPUT_DIR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "WaSPPnrEun12",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown ###Load required models\n",
        "from diffusers import AutoencoderKL, DDIMScheduler, DDPMScheduler, StableDiffusionPipeline, UNet2DConditionModel\n",
        "import torch\n",
        "import ipywidgets as widgets\n",
        "from io import BytesIO\n",
        "import requests\n",
        "import tqdm\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJajq43GuhcE"
      },
      "source": [
        "### Model Samples "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "I9k2EC7vtPOa",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "MODEL_SAMPLES = False #@param {type: 'boolean'}\n",
        "ANOTHER_MODEL_NAME = \"\" #@param\n",
        "prompt = \"marilyn monroe, illustration style\" #@param\n",
        "if MODEL_SAMPLES and not ANOTHER_MODEL_NAME:\n",
        "  pipe = StableDiffusionPipeline.from_pretrained(MODEL_NAME, torch_dtype=torch.float16)\n",
        "  pipe = pipe.to(\"cuda\")\n",
        "\n",
        "  if not os.path.exists(\"samples\"):\n",
        "    %mkdir \"samples\"\n",
        "    \n",
        "  image1 = pipe(prompt).images[0]\n",
        "  image1.save(\"samples/1.png\")\n",
        "\n",
        "  image2 = pipe(prompt).images[0]\n",
        "  image2.save(\"samples/2.png\")\n",
        "  plt.imshow(image2)\n",
        "\n",
        "elif MODEL_SAMPLES and ANOTHER_MODEL_NAME:\n",
        "  pipe = StableDiffusionPipeline.from_pretrained(ANOTHER_MODEL_NAME, torch_dtype=torch.float16)\n",
        "  pipe = pipe.to(\"cuda\")\n",
        "\n",
        "  if not os.path.exists(\"samples\"):\n",
        "    %mkdir \"samples\"\n",
        "\n",
        "  image1 = pipe(prompt).images[0]\n",
        "  image1.save(\"samples/1.png\")\n",
        "\n",
        "  image2 = pipe(prompt).images[0]\n",
        "  image2.save(\"samples/2.png\")\n",
        "  plt.imshow(image2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wpxiuDNYpnl"
      },
      "source": [
        "### Define Your Concepts List\n",
        "You can add multiple concepts here. Try tweaking `--max_train_steps` accordingly.\n",
        "It's a good idea to test class prompts in Stable Diffusion V2 before committing to them. If the images V2 generates at a CFG of 7 and 50 steps aren't great, consider a different class prompt. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "5vDpCxId1aCm"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "READ_PROMPT_FROM_TXTS = True\n",
        "token = \"zyc\" \n",
        "\n",
        "instance_dir_list = [\"zyc\"]\n",
        "num_class_images = [120]  \n",
        "\n",
        "class_prompt_list = [\"photo of a man\"]\n",
        "class_dir_list = [\"class/sd-man\"]\n",
        "\n",
        "\n",
        "dataset_dir = \"dataset/\"\n",
        "instance_dir_list = [dataset_dir + dir for dir in instance_dir_list]\n",
        "class_dir_list = [dataset_dir + dir for dir in class_dir_list]\n",
        "\n",
        "concepts_list = [\n",
        "\n",
        "    {\n",
        "       \"instance_prompt\":       token,\n",
        "       \"class_prompt\":          class_prompt_list[0],\n",
        "       \"instance_data_dir\":     instance_dir_list[0],\n",
        "       \"class_data_dir\":        class_dir_list[0],\n",
        "       \"num_class_images\":      num_class_images[0]\n",
        "    },\n",
        "    \n",
        "]\n",
        "\n",
        "# `class_data_dir` contains regularization images\n",
        "for concept in concepts_list:\n",
        "    os.makedirs(concept[\"instance_data_dir\"], exist_ok=True)\n",
        "\n",
        "with open(\"concepts_list.json\", \"w\") as f:\n",
        "    json.dump(concepts_list, f, indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "FlGN7EXcK8sw",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "GENERATE_PROMPT = False #@param {type: \"boolean\"}\n",
        "\n",
        "if READ_PROMPT_FROM_TXTS  and GENERATE_PROMPT:\n",
        "  from transformers import BlipProcessor, BlipForConditionalGeneration\n",
        "\n",
        "  processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-large\")\n",
        "  model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-large\", torch_dtype=torch.float16).to(\"cuda\")\n",
        "  \n",
        "  for instance_dir in instance_dir_list:\n",
        "    for filename in os.listdir(instance_dir):\n",
        "      \n",
        "      extension = filename.split(\".\")[-1]\n",
        "      if extension != \"txt\":\n",
        "\n",
        "        txtname = filename + \".txt\"\n",
        "        image = Image.open(instance_dir+\"/\"+filename).convert('RGB')\n",
        "\n",
        "        # text = \"a photo of\"\n",
        "        text = \"\"\n",
        "        inputs = processor(image, text, return_tensors=\"pt\").to(\"cuda\", torch.float16)\n",
        "\n",
        "        out = model.generate(**inputs)\n",
        "        out = processor.decode(out[0], skip_special_tokens=True)\n",
        "        prompt = out.replace(\"boy\",token).replace(\"man\", token).replace(\"male\", token).replace(\"asian\", \"\")\n",
        "        # prompt = out.replace(\"girl\",token).replace(\"woman\", token).replace(\"female\", token).replace(\"asian\", \"\")\n",
        "        print(prompt)\n",
        "        with open(instance_dir+\"/\"+txtname, 'w') as f:\n",
        "              f.write(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "0mZo6Ta6fh_N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "c93b38dd49884b828aefbee0f1d82d9a"
          ]
        },
        "outputId": "fd470b36-877e-4af7-e9bd-cd4a91eec450",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HBox(children=(Select(options=('Select an instance image to caption',), rows=25, value='Select an instance ima…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c93b38dd49884b828aefbee0f1d82d9a"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import ipywidgets as widgets\n",
        "from io import BytesIO\n",
        "#@markdown #Captions\n",
        "\n",
        "#@markdown - Open a tool to manually `create` captions or edit existing captions of the instance images.\n",
        "\n",
        "paths=\"\"\n",
        "out=\"\"\n",
        "widgets_l=\"\"\n",
        "\n",
        "instance_dir = 0 #@param\n",
        "DIR = instance_dir_list[instance_dir]\n",
        "def Caption(path):\n",
        "  \n",
        "    if path!=\"Select an instance image to caption\":\n",
        "      \n",
        "      name = os.path.basename(path)\n",
        "      ext=os.path.splitext(os.path.basename(path))[-1][1:]\n",
        "      if ext==\"jpg\" or \"JPG\":\n",
        "        ext=\"JPEG\"\n",
        "      else:\n",
        "        ext=\"PNG\"      \n",
        "\n",
        "      if os.path.exists(DIR + \"/\"+ name + '.txt'):\n",
        "        with open(DIR + \"/\" + name + '.txt', 'r') as f:\n",
        "            text = f.read()\n",
        "      else:\n",
        "        with open(DIR + \"/\" + name + '.txt', 'w') as f:\n",
        "            f.write(\"\")\n",
        "            with open(DIR + \"/\" + name + '.txt', 'r') as f:\n",
        "                text = f.read()   \n",
        "\n",
        "      img=Image.open(os.path.join(DIR,path))\n",
        "      img = img.convert('RGB').resize((420, 420))\n",
        "      image_bytes = BytesIO()\n",
        "      img.save(image_bytes, format=ext, qualiy=10)\n",
        "      image_bytes.seek(0)\n",
        "      image_data = image_bytes.read()\n",
        "      img= image_data\n",
        "      image = widgets.Image(\n",
        "          value=img,\n",
        "          width=420,\n",
        "          height=420\n",
        "      )\n",
        "      text_area = widgets.Textarea(value=text, description='', disabled=False, layout={'width': '500px', 'height': '120px'})\n",
        "      \n",
        "\n",
        "      def update_text(text):\n",
        "          with open(DIR+\"/\"+ name + '.txt', 'w') as f:\n",
        "              f.write(text)\n",
        "\n",
        "      button = widgets.Button(description='Save', button_style='success')\n",
        "      button.on_click(lambda b: update_text(text_area.value))\n",
        "      \n",
        "      # return widgets.VBox([widgets.HBox([text_area, button])])\n",
        "      return widgets.HBox([image, widgets.VBox([text_area, button])])\n",
        "\n",
        "\n",
        "paths = os.listdir(DIR)\n",
        "widgets_l = widgets.Select(options=[\"Select an instance image to caption\"]+paths, rows=25)\n",
        "\n",
        "\n",
        "out = widgets.Output()\n",
        "\n",
        "def click(change):\n",
        "    with out:\n",
        "        out.clear_output()\n",
        "        display(Caption(change.new))\n",
        "\n",
        "widgets_l.observe(click, names='value')\n",
        "display(widgets.HBox([widgets_l, out]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYH4tBO8uRWa",
        "outputId": "9a9109e7-4a2b-49bf-a407-214759d3c05f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Find results at:  /content/drive/MyDrive/stable_diffusion_weights/zyc\n",
            "MODEL:  runwayml/stable-diffusion-v1-5\n"
          ]
        }
      ],
      "source": [
        "print(\"Find results at: \", OUTPUT_DIR)\n",
        "print(\"MODEL: \", MODEL_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnBEZ19IrctK"
      },
      "source": [
        "### Define Testing Prompt List"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Pzr5jxEGrbtx"
      },
      "outputs": [],
      "source": [
        "man_prompts_list = [f\"{token} with wings\",\n",
        "           f\"{token} clothed in metal armor\"\n",
        "           ]\n",
        "               \n",
        "\n",
        "prompts_list = man_prompts_list\n",
        "\n",
        "with open(\"prompts_list.json\", \"w\") as f:\n",
        "    json.dump(prompts_list, f, indent=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define Steps setting List"
      ],
      "metadata": {
        "id": "O-r0Y574RR2w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "steps_setting = {\n",
        "    \"max_train_steps\": 800, \n",
        "    \"save_interval\": 200,\n",
        "    \"lr_warmup_steps\": 100,\n",
        "    \"save_min_steps\":0,\n",
        "    \"only_save_steps\": [600, 800]\n",
        "  }\n",
        "\n",
        "with open(\"steps_setting.json\", \"w\") as f:\n",
        "    json.dump(steps_setting, f, indent=4)"
      ],
      "metadata": {
        "id": "BqPC4bHXRPiY"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Settings"
      ],
      "metadata": {
        "id": "yF7_S0EPP9G0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "jghz8Ob_tbcE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "703106a7-0bd0-424c-b23b-dc90e2683520"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
            "\t`--num_processes` was set to a value of `1`\n",
            "\t`--num_machines` was set to a value of `1`\n",
            "\t`--mixed_precision` was set to a value of `'no'`\n",
            "\t`--num_cpu_threads_per_process` was set to `2` to improve out-of-box performance\n",
            "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
            "2023-03-02 21:33:38.817865: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-02 21:33:38.817955: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-02 21:33:38.817966: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "usage: train_dreambooth.py\n",
            "       [-h]\n",
            "       --pretrained_model_name_or_path\n",
            "       PRETRAINED_MODEL_NAME_OR_PATH\n",
            "       [--pretrained_vae_name_or_path PRETRAINED_VAE_NAME_OR_PATH]\n",
            "       [--revision REVISION]\n",
            "       [--tokenizer_name TOKENIZER_NAME]\n",
            "       [--instance_data_dir INSTANCE_DATA_DIR]\n",
            "       [--class_data_dir CLASS_DATA_DIR]\n",
            "       [--instance_prompt INSTANCE_PROMPT]\n",
            "       [--class_prompt CLASS_PROMPT]\n",
            "       [--save_sample_prompt SAVE_SAMPLE_PROMPT]\n",
            "       [--save_sample_negative_prompt SAVE_SAMPLE_NEGATIVE_PROMPT]\n",
            "       [--n_save_sample N_SAVE_SAMPLE]\n",
            "       [--save_guidance_scale SAVE_GUIDANCE_SCALE]\n",
            "       [--save_infer_steps SAVE_INFER_STEPS]\n",
            "       [--pad_tokens]\n",
            "       [--with_prior_preservation]\n",
            "       [--prior_loss_weight PRIOR_LOSS_WEIGHT]\n",
            "       [--num_class_images NUM_CLASS_IMAGES]\n",
            "       [--output_dir OUTPUT_DIR]\n",
            "       [--seed SEED]\n",
            "       [--resolution RESOLUTION]\n",
            "       [--center_crop]\n",
            "       [--train_text_encoder]\n",
            "       [--train_batch_size TRAIN_BATCH_SIZE]\n",
            "       [--sample_batch_size SAMPLE_BATCH_SIZE]\n",
            "       [--num_train_epochs NUM_TRAIN_EPOCHS]\n",
            "       [--max_train_steps MAX_TRAIN_STEPS]\n",
            "       [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]\n",
            "       [--gradient_checkpointing]\n",
            "       [--learning_rate LEARNING_RATE]\n",
            "       [--scale_lr]\n",
            "       [--lr_scheduler LR_SCHEDULER]\n",
            "       [--lr_warmup_steps LR_WARMUP_STEPS]\n",
            "       [--use_8bit_adam]\n",
            "       [--adam_beta1 ADAM_BETA1]\n",
            "       [--adam_beta2 ADAM_BETA2]\n",
            "       [--adam_weight_decay ADAM_WEIGHT_DECAY]\n",
            "       [--adam_epsilon ADAM_EPSILON]\n",
            "       [--max_grad_norm MAX_GRAD_NORM]\n",
            "       [--push_to_hub]\n",
            "       [--hub_token HUB_TOKEN]\n",
            "       [--hub_model_id HUB_MODEL_ID]\n",
            "       [--logging_dir LOGGING_DIR]\n",
            "       [--log_interval LOG_INTERVAL]\n",
            "       [--save_interval SAVE_INTERVAL]\n",
            "       [--only_save_steps ONLY_SAVE_STEPS]\n",
            "       [--save_min_steps SAVE_MIN_STEPS]\n",
            "       [--mixed_precision {no,fp16,bf16}]\n",
            "       [--not_cache_latents]\n",
            "       [--hflip]\n",
            "       [--local_rank LOCAL_RANK]\n",
            "       [--concepts_list CONCEPTS_LIST]\n",
            "       [--prompts_list PROMPTS_LIST]\n",
            "       [--read_prompts_from_txts]\n",
            "train_dreambooth.py: error: argument --only_save_steps: invalid int value: '[600,'\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/accelerate\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/accelerate/commands/accelerate_cli.py\", line 43, in main\n",
            "    args.func(args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/accelerate/commands/launch.py\", line 837, in launch_command\n",
            "    simple_launcher(args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/accelerate/commands/launch.py\", line 354, in simple_launcher\n",
            "    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)\n",
            "subprocess.CalledProcessError: Command '['/usr/bin/python3', 'train_dreambooth.py', '--pretrained_model_name_or_path=runwayml/stable-diffusion-v1-5', '--pretrained_vae_name_or_path=stabilityai/sd-vae-ft-mse', '--output_dir=/content/drive/MyDrive/stable_diffusion_weights/zyc', '--revision=fp16', '--with_prior_preservation', '--prior_loss_weight=1.0', '--seed=1337', '--resolution=512', '--train_batch_size=1', '--mixed_precision=fp16', '--use_8bit_adam', '--gradient_accumulation_steps=1', '--gradient_checkpointing', '--learning_rate=1e-6', '--lr_scheduler=polynomial', '--lr_warmup_steps=300', '--num_class_images=160', '--sample_batch_size=4', '--max_train_steps=800', '--save_interval=200', '--only_save_steps=[600,', '800]', '--concepts_list=concepts_list.json', '--prompts_list=prompts_list.json', '--n_save_sample=1', '--train_text_encoder', '--read_prompts_from_txts']' returned non-zero exit status 2.\n"
          ]
        }
      ],
      "source": [
        "# --train_text_encoder \\\n",
        "if READ_PROMPT_FROM_TXTS:\n",
        "  !accelerate launch train_dreambooth.py \\\n",
        "    --pretrained_model_name_or_path=$MODEL_NAME \\\n",
        "    --pretrained_vae_name_or_path=$VAE_NAME \\\n",
        "    --output_dir=$OUTPUT_DIR \\\n",
        "    --revision=\"fp16\" \\\n",
        "    --with_prior_preservation \\\n",
        "    --prior_loss_weight=1.0 \\\n",
        "    --seed=1337 \\\n",
        "    --resolution=512 \\\n",
        "    --train_batch_size=1 \\\n",
        "    --mixed_precision=\"fp16\" \\\n",
        "    --use_8bit_adam \\\n",
        "    --gradient_accumulation_steps=1 \\\n",
        "    --gradient_checkpointing \\\n",
        "    --learning_rate=1.5e-6 \\\n",
        "    --lr_scheduler=\"polynomial\" \\\n",
        "    --num_class_images=120 \\\n",
        "    --sample_batch_size=4 \\\n",
        "    --train_text_encoder \\\n",
        "    --concepts_list=\"concepts_list.json\" \\\n",
        "    --prompts_list=\"prompts_list.json\" \\\n",
        "    --steps_setting=\"steps_setting.json\" \\\n",
        "    --n_save_sample=2 \\\n",
        "    --read_prompts_from_txts "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --train_text_encoder \\\n",
        "if not READ_PROMPT_FROM_TXTS:\n",
        "if READ_PROMPT_FROM_TXTS:\n",
        "  !accelerate launch train_dreambooth.py \\\n",
        "    --pretrained_model_name_or_path=$MODEL_NAME \\\n",
        "    --pretrained_vae_name_or_path=$VAE_NAME \\\n",
        "    --output_dir=$OUTPUT_DIR \\\n",
        "    --revision=\"fp16\" \\\n",
        "    --with_prior_preservation \\\n",
        "    --prior_loss_weight=1.0 \\\n",
        "    --seed=1337 \\\n",
        "    --resolution=512 \\\n",
        "    --train_batch_size=1 \\\n",
        "    --mixed_precision=\"fp16\" \\\n",
        "    --use_8bit_adam \\\n",
        "    --gradient_accumulation_steps=1 \\\n",
        "    --gradient_checkpointing \\\n",
        "    --learning_rate=1.5e-6 \\\n",
        "    --lr_scheduler=\"polynomial\" \\\n",
        "    --num_class_images=120 \\\n",
        "    --sample_batch_size=4 \\\n",
        "    --train_text_encoder \\\n",
        "    --concepts_list=\"concepts_list.json\" \\\n",
        "    --prompts_list=\"prompts_list.json\" \\\n",
        "    --steps_setting=\"steps_setting.json\" \\\n",
        "    --n_save_sample=2"
      ],
      "metadata": {
        "id": "UiwOB8yGUKHQ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "MlhVPPmtEn-n",
        "outputId": "ca86b5aa-8e27-46f2-fa59-1838829d12ae",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-8458293ece4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mcol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfolders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"samples\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgridspec_kw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'hspace'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wspace'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ],
      "source": [
        "#@markdown Run to generate a grid of preview images from the last saved weights.\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "weights_folder = OUTPUT_DIR\n",
        "folders = sorted([f for f in os.listdir(weights_folder) if f != \"0\"], key=lambda x: int(x))\n",
        "\n",
        "row = len(folders)\n",
        "col = len(os.listdir(os.path.join(weights_folder, folders[0], \"samples\")))\n",
        "scale = 5\n",
        "fig, axes = plt.subplots(row, col, figsize=(col*scale, row*scale), gridspec_kw={'hspace': 0, 'wspace': 0})\n",
        "\n",
        "for i, folder in enumerate(folders):\n",
        "    folder_path = os.path.join(weights_folder, folder)\n",
        "    image_folder = os.path.join(folder_path, \"samples\")\n",
        "    images = [f for f in os.listdir(image_folder)]\n",
        "    \n",
        "    for j, image in enumerate(images):\n",
        "        if row == 1:\n",
        "            currAxes = axes[j]\n",
        "        else:\n",
        "            currAxes = axes[i, j]\n",
        "        if i == 0:\n",
        "            currAxes.set_title(prompts_list_token[j][3:15])\n",
        "        if j == 0:\n",
        "            currAxes.text(-0.1, 0.5, folder, rotation=0, va='center', ha='center', transform=currAxes.transAxes)\n",
        "        image_path = os.path.join(image_folder, image)\n",
        "        img = mpimg.imread(image_path)\n",
        "        currAxes.imshow(img, cmap='gray')\n",
        "        currAxes.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(f'{OUTPUT_DIR}/grid.png', dpi=72)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b-zMDxwFAQF7"
      },
      "outputs": [],
      "source": [
        "STOPHERE()  # a wrong function to force stop here before next step, you can skip this cell and continue run celles after this cell"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPXFqZt9cZam"
      },
      "source": [
        "## Testing your new model\n",
        "\n",
        "Once your model has finished training (or has reached a checkpoint you like), run the following cells to test it out."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "OUTPUT_DIR = \"stable_diffusion_weights/zyc\"\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/\" + OUTPUT_DIR"
      ],
      "metadata": {
        "id": "6J3DeMrkcGxY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "89Az5NUxOWdy"
      },
      "outputs": [],
      "source": [
        "#@markdown Specify the weights directory to use (leave blank for latest)\n",
        "WEIGHTS_DIR = \"/1000\" #@param {type:\"string\"}\n",
        "WEIGHTS_DIR = OUTPUT_DIR + WEIGHTS_DIR\n",
        "\n",
        "if WEIGHTS_DIR == OUTPUT_DIR:\n",
        "    from natsort import natsorted\n",
        "    from glob import glob\n",
        "    import os\n",
        "    WEIGHTS_DIR = natsorted(glob(OUTPUT_DIR + os.sep + \"*\"))[-1]\n",
        "\n",
        "print(f\"[*] WEIGHTS_DIR={WEIGHTS_DIR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5V8wgU0HN-Kq"
      },
      "source": [
        "#### Convert weights to ckpt to use in web UIs like AUTOMATIC1111."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dcXzsUyG1aCy"
      },
      "outputs": [],
      "source": [
        "CONVERT = False #@param {type:\"boolean\"}\n",
        "if CONVERT:\n",
        "  ckpt_path = WEIGHTS_DIR + \"/model.ckpt\"\n",
        "\n",
        "  half_arg = \"\"\n",
        "  #@markdown  Whether to convert to fp16, takes half the space (2GB).\n",
        "  fp16 = True #@param {type: \"boolean\"}\n",
        "  if fp16:\n",
        "      half_arg = \"--half\"\n",
        "  !python convert_diffusers_to_original_stable_diffusion.py --model_path $WEIGHTS_DIR  --checkpoint_path $ckpt_path $half_arg\n",
        "  print(f\"[*] Converted ckpt saved at {ckpt_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToNG4fd_dTbF"
      },
      "source": [
        "#### Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gW15FjffdTID"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import autocast\n",
        "from diffusers import StableDiffusionPipeline, DDIMScheduler\n",
        "from IPython.display import display\n",
        "\n",
        "model_path = WEIGHTS_DIR             # If you want to use previously trained model saved in gdrive, replace this with the full path of model in gdrive\n",
        "\n",
        "scheduler = DDIMScheduler(beta_start=0.00085, beta_end=0.012, beta_schedule=\"scaled_linear\", clip_sample=False, set_alpha_to_one=False)\n",
        "pipe = StableDiffusionPipeline.from_pretrained(model_path, scheduler=scheduler, safety_checker=None, torch_dtype=torch.float16).to(\"cuda\")\n",
        "\n",
        "g_cuda = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "oIzkltjpVO_f"
      },
      "outputs": [],
      "source": [
        "#@markdown Can set random seed here for reproducibility.\n",
        "g_cuda = torch.Generator(device='cuda')\n",
        "seed = 1500 #@param {type:\"number\"}\n",
        "g_cuda.manual_seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K6xoHWSsbcS3",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "prompt = \"lebron james\" #@param {type:\"string\"}\n",
        "negative_prompt = \"\" #@param {type:\"string\"}\n",
        "num_samples = 2 #@param {type:\"number\"}\n",
        "guidance_scale = 7.5 #@param {type:\"number\"}\n",
        "num_inference_steps = 50 #@param {type:\"number\"}\n",
        "height = 512 #@param {type:\"number\"}\n",
        "width = 512 #@param {type:\"number\"}\n",
        "\n",
        "with autocast(\"cuda\"), torch.inference_mode():\n",
        "    images = pipe(\n",
        "        prompt,\n",
        "        height=height,\n",
        "        width=width,\n",
        "        negative_prompt=negative_prompt,\n",
        "        num_images_per_prompt=num_samples,\n",
        "        num_inference_steps=num_inference_steps,\n",
        "        guidance_scale=guidance_scale,\n",
        "        generator=g_cuda\n",
        "    ).images\n",
        "\n",
        "for img in images:\n",
        "    display(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gLSpJwgoqYFS"
      },
      "outputs": [],
      "source": [
        "STOP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "WMCqQ5Tcdsm2"
      },
      "outputs": [],
      "source": [
        "#@markdown Run Gradio UI for generating images.\n",
        "import gradio as gr\n",
        "\n",
        "def inference(prompt, negative_prompt, num_samples, height=512, width=512, num_inference_steps=50, guidance_scale=7.5):\n",
        "    with torch.autocast(\"cuda\"), torch.inference_mode():\n",
        "        return pipe(\n",
        "                prompt, height=int(height), width=int(width),\n",
        "                negative_prompt=negative_prompt,\n",
        "                num_images_per_prompt=int(num_samples),\n",
        "                num_inference_steps=int(num_inference_steps), guidance_scale=guidance_scale,\n",
        "                generator=g_cuda\n",
        "            ).images\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            prompt = gr.Textbox(label=\"Prompt\", value=\"photo of zwx dog in a bucket\")\n",
        "            negative_prompt = gr.Textbox(label=\"Negative Prompt\", value=\"\")\n",
        "            run = gr.Button(value=\"Generate\")\n",
        "            with gr.Row():\n",
        "                num_samples = gr.Number(label=\"Number of Samples\", value=4)\n",
        "                guidance_scale = gr.Number(label=\"Guidance Scale\", value=7.5)\n",
        "            with gr.Row():\n",
        "                height = gr.Number(label=\"Height\", value=512)\n",
        "                width = gr.Number(label=\"Width\", value=512)\n",
        "            num_inference_steps = gr.Slider(label=\"Steps\", value=50)\n",
        "        with gr.Column():\n",
        "            gallery = gr.Gallery()\n",
        "\n",
        "    run.click(inference, inputs=[prompt, negative_prompt, num_samples, height, width, num_inference_steps, guidance_scale], outputs=gallery)\n",
        "\n",
        "demo.launch(debug=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "lJoOgLQHnC8L"
      },
      "outputs": [],
      "source": [
        "#@title (Optional) Delete diffuser and old weights and only keep the ckpt to free up drive space.\n",
        "\n",
        "#@markdown [ ! ] Caution, Only execute if you are sure u want to delete the diffuser format weights and only use the ckpt.\n",
        "import shutil\n",
        "from glob import glob\n",
        "import os\n",
        "for f in glob(OUTPUT_DIR+os.sep+\"*\"):\n",
        "    if f != WEIGHTS_DIR:\n",
        "        shutil.rmtree(f)\n",
        "        print(\"Deleted\", f)\n",
        "for f in glob(WEIGHTS_DIR+\"/*\"):\n",
        "    if not f.endswith(\".ckpt\") or not f.endswith(\".json\"):\n",
        "        try:\n",
        "            shutil.rmtree(f)\n",
        "        except NotADirectoryError:\n",
        "            continue\n",
        "        print(\"Deleted\", f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jXgi8HM4c-DA"
      },
      "outputs": [],
      "source": [
        "#@title Free runtime memory\n",
        "exit()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c93b38dd49884b828aefbee0f1d82d9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aaa2bf3fb7aa4d68a11ca5e56cc903f9",
              "IPY_MODEL_f3ba2067804c4dfb9fc3c0f71ebc0d08"
            ],
            "layout": "IPY_MODEL_99eafde3c37b4445b56a256786fae0f7"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}